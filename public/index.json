[{"content":"\u003cp\u003eIntegrating Ollama with LangChainGo opens up exciting possibilities for developers looking to harness the power of AI in their Go projects. Ollama, a language model developed by Gemma, offers advanced natural language processing capabilities, while LangChainGo provides seamless integration with Go, allowing developers to build production-ready AI applications with ease.\u003c/p\u003e\n\u003cp\u003eHere\u0026rsquo;s a closer look at how you can leverage Ollama with LangChainGo to create sophisticated AI applications:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epackage main\n\nimport (\n\t\u0026#34;context\u0026#34;\n\t\u0026#34;flag\u0026#34;\n\t\u0026#34;fmt\u0026#34;\n\t\u0026#34;log\u0026#34;\n\n\t\u0026#34;github.com/tmc/langchaingo/llms\u0026#34;\n\t\u0026#34;github.com/tmc/langchaingo/llms/ollama\u0026#34;\n)\n\nfunc main() {\n\tmodelName := flag.String(\u0026#34;model\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;ollama model name\u0026#34;)\n\tquery := flag.String(\u0026#34;query\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;query to the model\u0026#34;)\n\tstream := flag.Bool(\u0026#34;stream\u0026#34;, false, \u0026#34;stream output\u0026#34;)\n\tflag.Parse()\n\n\tllm, err := ollama.New(ollama.WithModel(*modelName))\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tctx := context.Background()\n\tif !*stream {\n\t\tcompletion, err := llms.GenerateFromSinglePrompt(ctx, llm, *query)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\n\t\tfmt.Println(\u0026#34;Response:\\n\u0026#34;, completion)\n\t} else {\n\t\t_, err = llms.GenerateFromSinglePrompt(ctx, llm, *query,\n\t\t\tllms.WithStreamingFunc(func(ctx context.Context, chunk []byte) error {\n\t\t\t\tfmt.Printf(\u0026#34;chunk len=%d: %s\\n\u0026#34;, len(chunk), chunk)\n\t\t\t\treturn nil\n\t\t\t}))\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t}\n\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThis code snippet demonstrates how to utilize Ollama with LangChainGo to generate responses from a given prompt. With Ollama\u0026rsquo;s powerful language modeling capabilities and LangChainGo\u0026rsquo;s seamless integration, developers can easily incorporate AI-driven features into their Go applications.\u003c/p\u003e\n\u003cp\u003eAn interesting aspect to note is that while LangChainGo offers a convenient API standardized across LLM providers, its use is by no means required for this sample. Ollama itself provides a Go API as part of its structure, allowing developers to use it externally as well.\u003c/p\u003e\n\u003cp\u003eWhether you\u0026rsquo;re building chatbots, language translation tools, or text analysis systems, Ollama and LangChainGo provide the tools and resources necessary to create sophisticated AI solutions in Go.\u003c/p\u003e\n\u003cp\u003eIn conclusion, the combination of Ollama and LangChainGo represents a significant advancement in the realm of AI development in Go. By leveraging these technologies, developers can unlock new opportunities for innovation and create AI-powered applications that meet the demands of today\u0026rsquo;s dynamic digital landscape.\u003c/p\u003e\n\u003cp\u003eThe complete code is \u003ca href=\"https://github.com/bindrad/using-ollama-with-langchaingo\"\u003eavailable at GitHub\u003c/a\u003e.\u003c/p\u003e\n","description":"","image":"/images/langchaingo-ollama.jpeg","permalink":"https://bindrad.github.io/blogs/ollama-langchain/","title":"Exploring the Power of Ollama with LangChainGo: Building AI Applications in Go"},{"content":"\u003cp\u003eContainers are small, lightweight bundles containing one or more applications and their dependencies, essential for running code. The beauty of containers lies in their ability to package all necessary components, making applications highly portable.\u003c/p\u003e\n\u003ch2 id=\"why-does-a-container-need-persistent-storage\"\u003eWhy does a Container Need Persistent Storage?\u003c/h2\u003e\n\u003cp\u003eContainers are ephemeral, necessitating a means to store persistent data. While containers carry code, runtime, and dependencies wherever they go, they don\u0026rsquo;t bring along application-generated data to maintain a lightweight footprint. Real-world applications, especially databases like Postgres, require data persistence. If a Postgres container generates data, it\u0026rsquo;s crucial to retain that data even if the container is moved or restarted. This is where persistent storage becomes essential.\u003c/p\u003e\n\u003ch2 id=\"how-to-attach-a-volume-to-a-container\"\u003eHow to Attach a Volume to a Container?\u003c/h2\u003e\n\u003cp\u003eOne effective method is by utilizing Docker volumes. Volumes are specifically designed to support stateful applications, ensuring that data is stored permanently in a persistent storage solution.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s demonstrate this by mounting a volume to a container and verifying the content of same volume in another container:\u003c/p\u003e\n\u003cp\u003eRun a alpine container and mount volume called \u003cmark\u003edemo\u003c/mark\u003e to it.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ docker run -it -v demo:/demo alpine\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eCheck the file system, you can see \u003cmark\u003edemo\u003c/mark\u003e directory.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e/ # ls\nbin    demo   dev    etc    home   lib    media  mnt    opt    proc   root   run    sbin   srv    sys    tmp    usr    var\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eLet\u0026rsquo;s change the directory and create a file inside it with some content.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e/ # cd demo/\n/demo # echo \u0026#34;Hello World!\u0026#34; \u0026gt; demo.txt\n/demo # cat demo.txt\nHello World!\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eExit from alpine container, container will stop running as there is no process running inside it.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e/demo # exit\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eNow, let\u0026rsquo;s create another container using Fedora Docker image. Run the fedora docker image.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ docker run -it -v demo:/lets_verify fedora\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eCheck the file system, you can see \u003cmark\u003elets_verify\u003c/mark\u003e directory.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e# ls\nafs  bin  boot  dev  etc  home  lets_verify  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eChange the directory to \u003cmark\u003elets_verify\u003c/mark\u003e and check the content of it. We can see the exact same content that we wrote in alpine container. This is the beauty of volumes in container, we can persist data while using containers.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e# cd lets_verify/\n# ls\ndemo.txt\n# cat demo.txt\nHello World!\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eExit from the container\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e[root@66ecfcdb8397 lets_verify]# exit\nexit\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAdditionally, you can manually create volumes and configure permissions. For more details, consult the \u003ca href=\"https://docs.docker.com/storage/volumes/\"\u003eofficial Docker documentation\u003c/a\u003e.\u003c/p\u003e\n","description":"","image":"/images/volumes.gif","permalink":"https://bindrad.github.io/blogs/container-volumes/","title":"From Ephemeral to Everlasting: Understanding Container Volumes"},{"content":"\u003cp\u003eContainers have emerged as a revolutionary way to deploy applications, offering a unique approach to running software in an isolated environment. This isolation ensures that your application operates independently, safeguarding both the applications running on the host machine and the host machine itself.\nA container provides a contained space to your application where it is shielded from the external interference of the host machine or other applications running on host machines.\u003c/p\u003e\n\u003ch2 id=\"in-the-container-jungle-making-sense-of-docker-and-containers\"\u003eIn the Container Jungle: Making Sense of Docker and Containers\u003c/h2\u003e\n\u003cp\u003eA major confusion lies in the interchangeable use of terms like \u0026ldquo;Docker\u0026rdquo; and \u0026ldquo;Containers.\u0026rdquo; It\u0026rsquo;s crucial to clarify the misunderstanding that between Docker and broader concept of containers, as the two are distinct entities.\nDocker is not just a technology; it\u0026rsquo;s also a company that introduced and popularized containerization. When people refer to \u0026ldquo;Docker containers,\u0026rdquo; they may be referring to containers managed by the Docker platform. Docker provides an end-to-end solution for container development, deployment, and management.\nWhereas Containers existed before Docker. The concept of containers and container-like technology has been around for a long time. Docker simplified and popularized the use of containers, but it\u0026rsquo;s important to understand that containers, as a general concept, are not exclusive to Docker.\u003c/p\u003e\n\u003ch2 id=\"linux-namespaces-creating-isolated-environments\"\u003eLinux Namespaces: Creating Isolated Environments\u003c/h2\u003e\n\u003cp\u003eLinux namespaces are a kernel-level feature that empowers processes with isolated and separate views of specific system resources. This abstraction allows the creation of lightweight and independent environments for processes. Various namespace types, including network, mount, cgroup, user, and PID, offer isolation for distinct resources. The unshare command facilitates namespace creation, and the setns command associates processes with existing namespaces. Additionally, the chroot command changes the root directory, establishing an isolated filesystem environment.\u003c/p\u003e\n\u003ch2 id=\"control-groups-cgroups-managing-resources-dynamically\"\u003eControl Groups (cgroups): Managing Resources Dynamically\u003c/h2\u003e\n\u003cp\u003eControl Groups, or cgroups, represent a crucial Linux kernel feature for allocating and managing system resources among groups of processes. In the context of containerization, cgroups are instrumental in controlling and limiting resource consumption for containerized applications. This includes dynamic adjustments to resource limits, real-time monitoring, and statistics collection. Container runtimes leverage the cgroup API to interact with the kernel, ensuring effective resource management.\u003c/p\u003e\n\u003ch2 id=\"integration-of-namespaces-and-cgroups\"\u003eIntegration of Namespaces and cgroups\u003c/h2\u003e\n\u003cp\u003eThe synergy between Linux namespaces and cgroups is pivotal for comprehensive containerization. While namespaces provide isolation for various system resources, cgroups facilitate dynamic resource allocation and management. Together, they enable the creation of isolated, resource-controlled environments for applications. This integration forms the foundation for container runtimes, empowering developers with efficient and portable solutions for deploying and managing software.\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eIn conclusion, Linux namespaces and cgroups are integral components of containerization, offering a robust framework for creating isolated and resource-controlled environments. Understanding the interplay between these kernel features provides developers and operators with insights into building efficient and scalable containerized solutions in today\u0026rsquo;s dynamic computing landscape.\u003c/p\u003e\n","description":"","image":"/images/containers_blog.png","permalink":"https://bindrad.github.io/blogs/containers/","title":"Exploring Containerization: Unveiling the Core Concepts and Technologies"}]